{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iteration_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkN4Zf7bkAvD8YrRk2s/TY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0e4abe461ab4b8abb6a0855b58014ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_77526d4c53c948978736b540f815f745",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92ea43ceb06540e3b4ab6c21994f5f5a",
              "IPY_MODEL_c551b270720f4940a2b8a676f32b5b83"
            ]
          }
        },
        "77526d4c53c948978736b540f815f745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92ea43ceb06540e3b4ab6c21994f5f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_c7579050050e468fae243d1a2e8e6128",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.60MB of 0.60MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3b335b931004cb8a0774d07e77c840b"
          }
        },
        "c551b270720f4940a2b8a676f32b5b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e00f753421745499c669b96a98deb11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0aad42ad70cd4732a6877c6e9b555b4a"
          }
        },
        "c7579050050e468fae243d1a2e8e6128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3b335b931004cb8a0774d07e77c840b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e00f753421745499c669b96a98deb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0aad42ad70cd4732a6877c6e9b555b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/askmuhsin/weights_heist_eva7/blob/main/S5/nbs/iteration_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_psZb8wqJOLJ"
      },
      "source": [
        "## Target\n",
        "- Iteration #2\n",
        "- add image augmentations.\n",
        "  ```python\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomRotation((-8., 8.)),\n",
        "    transforms.GaussianBlur(kernel_size=(3, 9), sigma=(0.1, 5.)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.5, p=0.2),\n",
        "    transforms.RandomAffine(degrees=8., translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
        "    ```\n",
        "\n",
        "## Result\n",
        "  - Parameters - 7,936\n",
        "  - max_test_accuracy \t\t- 86.94\t[EPOCH -- 15]\n",
        "  - max_train_accuracy \t\t- 91.63\t[EPOCH -- 15]\n",
        "  - test_accuracy @ epoch 15 \t- 86.94\n",
        "  - train_accuracy @ epoch 15 \t- 91.63\n",
        "\n",
        "## Analysis\n",
        "- saw a dip in performance. but both the the train and test accuracies has decreased.\n",
        "- thinking the augmentation strategy was too strong. will reduce in on the next iteration to just rotation, gaussianblur, randomaffince, and colorjitter.\n",
        "- while also reducing the parameters of rotation degree, translate, and scale values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N71Dva3CIsfN",
        "outputId": "dcd9d016-e385-498f-ecc0-da99594edbb8"
      },
      "source": [
        "! pip install torchsummary\n",
        "! pip install wandb -qqq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_WwFxpSKgzJ"
      },
      "source": [
        "from __future__ import print_function\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FanHG-hcIqR"
      },
      "source": [
        "# Logging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "KdRzKRGdcLje",
        "outputId": "21ec569c-b422-4497-e661-996689112440"
      },
      "source": [
        "wandb.login()\n",
        "\n",
        "wandb.init(\n",
        "    project='s5_coding_drill_down',\n",
        "    entity='weights_heist_eva7',\n",
        "    tags=['iteration_2'],\n",
        "    name='image augmentations',\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maskmuhsin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/weights_heist_eva7/s5_coding_drill_down/runs/2ywxfobh\" target=\"_blank\">image augmentations</a></strong> to <a href=\"https://wandb.ai/weights_heist_eva7/s5_coding_drill_down\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fdc5f35f450>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/weights_heist_eva7/s5_coding_drill_down/runs/2ywxfobh?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q71_H6n0LMo3"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj9kOSklKnEd"
      },
      "source": [
        "def setup_env():\n",
        "  SEED = 1\n",
        "  cuda = torch.cuda.is_available()\n",
        "  \n",
        "  torch.manual_seed(SEED)\n",
        "  if cuda:\n",
        "      torch.cuda.manual_seed(SEED)\n",
        "  \n",
        "  device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "  return cuda, device"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaW97aGtLERJ",
        "outputId": "c3195009-0c4b-4282-f6ec-266fc419b80e"
      },
      "source": [
        "cuda, device = setup_env()\n",
        "cuda, device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, device(type='cuda'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7Io6J27tnJP"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQhZyXIyZVhz"
      },
      "source": [
        "def train_model(model, device, train_loader, optimizer, epoch):\n",
        "  train_batch_loss = []\n",
        "  train_batch_acc = []\n",
        "\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_batch_loss.append(loss.item())\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # Update pbar-tqdm\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_batch_acc.append(100*correct/processed)\n",
        "  \n",
        "  return train_batch_loss, train_batch_acc\n",
        "\n",
        " \n",
        "def test_model(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_acc"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKsbOCWYI6Np"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJus1of7LPgg"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03JAD0-eLQZY"
      },
      "source": [
        "train_transforms = transforms.Compose(\n",
        "  [\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomRotation((-8., 8.)),\n",
        "    transforms.GaussianBlur(kernel_size=(3, 9), sigma=(0.1, 5.)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.5, p=0.2),\n",
        "    transforms.RandomAffine(degrees=8., translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) \n",
        "  ]\n",
        ")\n",
        "\n",
        "test_transforms = transforms.Compose(\n",
        "  [\n",
        "    # transforms.Resize((28, 28)),\n",
        "    # transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) \n",
        "  ]\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZCqFXjzLRAW",
        "outputId": "caddca7e-3c01-4ef6-f3a0-0c15ea335773"
      },
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = {\n",
        "    'shuffle': True,\n",
        "    'batch_size': 128,\n",
        "    'num_workers': 2,\n",
        "    'pin_memory': True\n",
        "} if cuda else {\n",
        "    'shuffle': True,\n",
        "    'batch_size': 64,\n",
        "}\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2exIU9q3hUkM"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igbACzRFLRZB"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaNO_jDZLSXv"
      },
      "source": [
        "dropout_value = 0.1\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=12, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 26\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=12, out_channels=18, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(18),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 24\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=18, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 24\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=12, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 10\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=12, out_channels=14, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(14),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 6\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=14, out_channels=14, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(14),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 6\n",
        "        \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        ) # output_size = 1\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=14, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(10),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        ) \n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.gap(x)        \n",
        "        x = self.convblock8(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT_uK7VQNo6V",
        "outputId": "a29479b8-ad83-4da7-8e7d-ff1c8fa049ca"
      },
      "source": [
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 12, 26, 26]             108\n",
            "              ReLU-2           [-1, 12, 26, 26]               0\n",
            "       BatchNorm2d-3           [-1, 12, 26, 26]              24\n",
            "           Dropout-4           [-1, 12, 26, 26]               0\n",
            "            Conv2d-5           [-1, 18, 24, 24]           1,944\n",
            "              ReLU-6           [-1, 18, 24, 24]               0\n",
            "       BatchNorm2d-7           [-1, 18, 24, 24]              36\n",
            "           Dropout-8           [-1, 18, 24, 24]               0\n",
            "            Conv2d-9            [-1, 8, 24, 24]             144\n",
            "        MaxPool2d-10            [-1, 8, 12, 12]               0\n",
            "           Conv2d-11           [-1, 12, 10, 10]             864\n",
            "             ReLU-12           [-1, 12, 10, 10]               0\n",
            "      BatchNorm2d-13           [-1, 12, 10, 10]              24\n",
            "          Dropout-14           [-1, 12, 10, 10]               0\n",
            "           Conv2d-15             [-1, 12, 8, 8]           1,296\n",
            "             ReLU-16             [-1, 12, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 12, 8, 8]              24\n",
            "          Dropout-18             [-1, 12, 8, 8]               0\n",
            "           Conv2d-19             [-1, 14, 6, 6]           1,512\n",
            "             ReLU-20             [-1, 14, 6, 6]               0\n",
            "      BatchNorm2d-21             [-1, 14, 6, 6]              28\n",
            "          Dropout-22             [-1, 14, 6, 6]               0\n",
            "           Conv2d-23             [-1, 14, 6, 6]           1,764\n",
            "             ReLU-24             [-1, 14, 6, 6]               0\n",
            "      BatchNorm2d-25             [-1, 14, 6, 6]              28\n",
            "          Dropout-26             [-1, 14, 6, 6]               0\n",
            "        AvgPool2d-27             [-1, 14, 1, 1]               0\n",
            "           Conv2d-28             [-1, 10, 1, 1]             140\n",
            "================================================================\n",
            "Total params: 7,936\n",
            "Trainable params: 7,936\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.70\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.73\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqFnKXljLTnl"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Z3gu2IgPMd"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWZWPIJzLUyL",
        "outputId": "19dba866-b14b-4465-b2fd-cfc73258117a"
      },
      "source": [
        "logs = []\n",
        "EPOCHS = 25\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train_batch_loss, train_batch_acc = train_model(\n",
        "      model, device, train_loader, optimizer, epoch\n",
        "    )\n",
        "    train_loss = np.mean(train_batch_loss)\n",
        "    train_acc = np.mean(train_batch_acc)\n",
        "    \n",
        "    test_loss, test_acc = test_model(\n",
        "        model, device, test_loader\n",
        "    )\n",
        "    log_temp = {\n",
        "        \"epoch\": epoch,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"test_acc\": test_acc,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"test_loss\": test_loss,\n",
        "        \"lr\": optimizer.param_groups[0]['lr'],\n",
        "    }\n",
        "    wandb.log(log_temp)\n",
        "    logs.append(log_temp)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.6338664293289185 Batch_id=468 Accuracy=54.69: 100%|██████████| 469/469 [01:11<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4117, Accuracy: 6103/10000 (61.03%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.4190286099910736 Batch_id=468 Accuracy=80.42: 100%|██████████| 469/469 [01:10<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.5110, Accuracy: 6479/10000 (64.79%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.5222573280334473 Batch_id=468 Accuracy=85.14: 100%|██████████| 469/469 [01:10<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.1624, Accuracy: 7353/10000 (73.53%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.28120115399360657 Batch_id=468 Accuracy=87.38: 100%|██████████| 469/469 [01:13<00:00,  6.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0648, Accuracy: 7299/10000 (72.99%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.2304663062095642 Batch_id=468 Accuracy=88.28: 100%|██████████| 469/469 [01:12<00:00,  6.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8812, Accuracy: 7716/10000 (77.16%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.49377110600471497 Batch_id=468 Accuracy=89.19: 100%|██████████| 469/469 [01:11<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8564, Accuracy: 7853/10000 (78.53%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.224869966506958 Batch_id=468 Accuracy=89.54: 100%|██████████| 469/469 [01:12<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7182, Accuracy: 8151/10000 (81.51%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.4435989558696747 Batch_id=468 Accuracy=90.14: 100%|██████████| 469/469 [01:12<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7396, Accuracy: 8124/10000 (81.24%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.31660112738609314 Batch_id=468 Accuracy=90.19: 100%|██████████| 469/469 [01:13<00:00,  6.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8671, Accuracy: 7998/10000 (79.98%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.29892751574516296 Batch_id=468 Accuracy=90.65: 100%|██████████| 469/469 [01:12<00:00,  6.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6112, Accuracy: 8399/10000 (83.99%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.39145588874816895 Batch_id=468 Accuracy=90.79: 100%|██████████| 469/469 [01:11<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5977, Accuracy: 8445/10000 (84.45%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.22161388397216797 Batch_id=468 Accuracy=91.09: 100%|██████████| 469/469 [01:12<00:00,  6.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8258, Accuracy: 7958/10000 (79.58%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.3797900676727295 Batch_id=468 Accuracy=90.88: 100%|██████████| 469/469 [01:12<00:00,  6.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8134, Accuracy: 7892/10000 (78.92%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.22499801218509674 Batch_id=468 Accuracy=91.18: 100%|██████████| 469/469 [01:11<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6646, Accuracy: 8387/10000 (83.87%)\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.20941764116287231 Batch_id=468 Accuracy=91.53: 100%|██████████| 469/469 [01:11<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5316, Accuracy: 8694/10000 (86.94%)\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.31109723448753357 Batch_id=468 Accuracy=91.44: 100%|██████████| 469/469 [01:11<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6797, Accuracy: 8321/10000 (83.21%)\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.2649717628955841 Batch_id=468 Accuracy=91.59: 100%|██████████| 469/469 [01:11<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7052, Accuracy: 8298/10000 (82.98%)\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.20549069344997406 Batch_id=468 Accuracy=91.72: 100%|██████████| 469/469 [01:11<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5917, Accuracy: 8391/10000 (83.91%)\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.24206103384494781 Batch_id=468 Accuracy=91.68: 100%|██████████| 469/469 [01:12<00:00,  6.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6515, Accuracy: 8260/10000 (82.60%)\n",
            "\n",
            "EPOCH: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.31588196754455566 Batch_id=468 Accuracy=91.92: 100%|██████████| 469/469 [01:11<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5654, Accuracy: 8492/10000 (84.92%)\n",
            "\n",
            "EPOCH: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.30082273483276367 Batch_id=468 Accuracy=91.97: 100%|██████████| 469/469 [01:12<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6406, Accuracy: 8437/10000 (84.37%)\n",
            "\n",
            "EPOCH: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.33571699261665344 Batch_id=468 Accuracy=92.05: 100%|██████████| 469/469 [01:11<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5451, Accuracy: 8607/10000 (86.07%)\n",
            "\n",
            "EPOCH: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.33419784903526306 Batch_id=468 Accuracy=91.95: 100%|██████████| 469/469 [01:11<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6737, Accuracy: 8301/10000 (83.01%)\n",
            "\n",
            "EPOCH: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.4368160665035248 Batch_id=468 Accuracy=92.16: 100%|██████████| 469/469 [01:11<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6074, Accuracy: 8434/10000 (84.34%)\n",
            "\n",
            "EPOCH: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
            "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
            "Loss=0.24825094640254974 Batch_id=468 Accuracy=92.15: 100%|██████████| 469/469 [01:11<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6466, Accuracy: 8349/10000 (83.49%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "d0e4abe461ab4b8abb6a0855b58014ab",
            "77526d4c53c948978736b540f815f745",
            "92ea43ceb06540e3b4ab6c21994f5f5a",
            "c551b270720f4940a2b8a676f32b5b83",
            "c7579050050e468fae243d1a2e8e6128",
            "d3b335b931004cb8a0774d07e77c840b",
            "1e00f753421745499c669b96a98deb11",
            "0aad42ad70cd4732a6877c6e9b555b4a"
          ]
        },
        "id": "8ALF_Z6Kas91",
        "outputId": "add9edf4-b2eb-4d09-cf27-3878c3441afc"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 663... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0e4abe461ab4b8abb6a0855b58014ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.58MB of 0.58MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁▂▄▄▅▆▇▆▆▇▇▆▆▇█▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>test_loss</td><td>▇█▆▅▃▃▂▂▃▂▁▃▃▂▁▂▂▁▂▁▂▁▂▂▂</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇████████████████████</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>test_acc</td><td>83.49</td></tr><tr><td>test_loss</td><td>0.64661</td></tr><tr><td>train_acc</td><td>92.33268</td></tr><tr><td>train_loss</td><td>0.2511</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 12 artifact file(s) and 1 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">image augmentations</strong>: <a href=\"https://wandb.ai/weights_heist_eva7/s5_coding_drill_down/runs/2ywxfobh\" target=\"_blank\">https://wandb.ai/weights_heist_eva7/s5_coding_drill_down/runs/2ywxfobh</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211023_155344-2ywxfobh/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbzF26Q6lRII"
      },
      "source": [
        "end_epoch = 15\n",
        "logs_df = pd.DataFrame(logs)\n",
        "logs_df = logs_df[:end_epoch]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9FNZosGlnyW",
        "outputId": "cc85b7df-8e07-4be0-cf71-67490cd2828f"
      },
      "source": [
        "max_test_acc = logs_df.test_acc.max()\n",
        "max_test_epoch = list(logs_df[logs_df.test_acc==max_test_acc].epoch)[0]\n",
        "max_train_acc = logs_df.train_acc.max()\n",
        "max_train_epoch = list(logs_df[logs_df.train_acc==max_train_acc].epoch)[0]\n",
        "test_acc = logs_df[logs_df.epoch==end_epoch].test_acc.item()\n",
        "train_acc = logs_df[logs_df.epoch==end_epoch].train_acc.item()\n",
        "\n",
        "print(\n",
        "f\"\"\"\n",
        "  - max_test_accuracy \\t\\t- {round(max_test_acc, 2)}\\t[EPOCH -- {max_test_epoch}]\n",
        "  - max_train_accuracy \\t\\t- {round(max_train_acc, 2)}\\t[EPOCH -- {max_train_epoch}]\n",
        "  - test_accuracy @ epoch 15 \\t- {round(test_acc, 2)}\n",
        "  - train_accuracy @ epoch 15 \\t- {round(train_acc, 2)}\n",
        "\"\"\"\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  - max_test_accuracy \t\t- 86.94\t[EPOCH -- 15]\n",
            "  - max_train_accuracy \t\t- 91.63\t[EPOCH -- 15]\n",
            "  - test_accuracy @ epoch 15 \t- 86.94\n",
            "  - train_accuracy @ epoch 15 \t- 91.63\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GldOPcSXnfs8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}